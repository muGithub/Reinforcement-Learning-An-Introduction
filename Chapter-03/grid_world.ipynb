{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grid_world.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muGithub/Reinforcement-Learning-An-Introduction/blob/master/Chapter-03/grid_world.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Ej8xSZ6w3qsb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#######################################################################\n",
        "# Copyright (C)                                                       #\n",
        "# 2016-2018 Shangtong Zhang(zhangshangtong.cpp@gmail.com)             #\n",
        "# 2016 Kenta Shimada(hyperkentakun@gmail.com)                         #\n",
        "# Permission given to modify the code as long as you keep this        #\n",
        "# declaration at the top                                              #\n",
        "#######################################################################\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.table import Table\n",
        "\n",
        "WORLD_SIZE = 5\n",
        "A_POS = [0, 1]\n",
        "A_PRIME_POS = [4, 1]\n",
        "B_POS = [0, 3]\n",
        "B_PRIME_POS = [2, 3]\n",
        "DISCOUNT = 0.9\n",
        "\n",
        "# left, up, right, down\n",
        "ACTIONS = [np.array([0, -1]),\n",
        "           np.array([-1, 0]),\n",
        "           np.array([0, 1]),\n",
        "           np.array([1, 0])]\n",
        "ACTION_PROB = 0.25\n",
        "\n",
        "def step(state, action):\n",
        "    if state == A_POS:\n",
        "        return A_PRIME_POS, 10\n",
        "    if state == B_POS:\n",
        "        return B_PRIME_POS, 5\n",
        "\n",
        "    state = np.array(state)\n",
        "    next_state = (state + action).tolist()\n",
        "    x, y = next_state\n",
        "    if x < 0 or x >= WORLD_SIZE or y < 0 or y >= WORLD_SIZE:\n",
        "        reward = -1.0\n",
        "        next_state = state\n",
        "    else:\n",
        "        reward = 0\n",
        "    return next_state, reward\n",
        "\n",
        "def draw_image(image):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_axis_off()\n",
        "    tb = Table(ax, bbox=[0, 0, 1, 1])\n",
        "\n",
        "    nrows, ncols = image.shape\n",
        "    width, height = 1.0 / ncols, 1.0 / nrows\n",
        "\n",
        "    # Add cells\n",
        "    for (i,j), val in np.ndenumerate(image):\n",
        "        # Index either the first or second item of bkg_colors based on\n",
        "        # a checker board pattern\n",
        "        idx = [j % 2, (j + 1) % 2][i % 2]\n",
        "        color = 'white'\n",
        "\n",
        "        tb.add_cell(i, j, width, height, text=val, \n",
        "                    loc='center', facecolor=color)\n",
        "\n",
        "    # Row Labels...\n",
        "    for i, label in enumerate(range(len(image))):\n",
        "        tb.add_cell(i, -1, width, height, text=label+1, loc='right', \n",
        "                    edgecolor='none', facecolor='none')\n",
        "    # Column Labels...\n",
        "    for j, label in enumerate(range(len(image))):\n",
        "        tb.add_cell(-1, j, width, height/2, text=label+1, loc='center', \n",
        "                           edgecolor='none', facecolor='none')\n",
        "    ax.add_table(tb)\n",
        "\n",
        "def figure_3_2():\n",
        "    value = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
        "    while True:\n",
        "        # keep iteration until convergence\n",
        "        new_value = np.zeros(value.shape)\n",
        "        for i in range(0, WORLD_SIZE):\n",
        "            for j in range(0, WORLD_SIZE):\n",
        "                for action in ACTIONS:\n",
        "                    (next_i, next_j), reward = step([i, j], action)\n",
        "                    # bellman equation\n",
        "                    new_value[i, j] += ACTION_PROB * (reward + DISCOUNT * value[next_i, next_j])\n",
        "        if np.sum(np.abs(value - new_value)) < 1e-4:\n",
        "            draw_image(np.round(new_value, decimals=2))\n",
        "            plt.savefig('/content/figure_3_2.png')\n",
        "            plt.close()\n",
        "            break\n",
        "        value = new_value\n",
        "\n",
        "def figure_3_5():\n",
        "    value = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
        "    while True:\n",
        "        # keep iteration until convergence\n",
        "        new_value = np.zeros(value.shape)\n",
        "        for i in range(0, WORLD_SIZE):\n",
        "            for j in range(0, WORLD_SIZE):\n",
        "                values = []\n",
        "                for action in ACTIONS:\n",
        "                    (next_i, next_j), reward = step([i, j], action)\n",
        "                    # value iteration\n",
        "                    values.append(reward + DISCOUNT * value[next_i, next_j])\n",
        "                new_value[i, j] = np.max(values)\n",
        "        if np.sum(np.abs(new_value - value)) < 1e-4:\n",
        "            draw_image(np.round(new_value, decimals=2))\n",
        "            plt.savefig('/content/figure_3_5.png')\n",
        "            plt.close()\n",
        "            break\n",
        "        value = new_value\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-PR82CiYNor_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "figure_3_2()\n",
        "figure_3_5()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}